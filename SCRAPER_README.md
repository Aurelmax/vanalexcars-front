# ü§ñ Scraper ImporteMoi - Documentation

Syst√®me automatis√© de scraping et d'import de v√©hicules depuis ImporteMoi.fr vers votre Payload CMS.

## üìã Table des mati√®res

- [Installation](#installation)
- [Configuration](#configuration)
- [Utilisation](#utilisation)
- [Automatisation](#automatisation)
- [Architecture](#architecture)
- [Troubleshooting](#troubleshooting)

---

## üöÄ Installation

### 1. V√©rifier les d√©pendances

Toutes les d√©pendances sont d√©j√† install√©es dans le projet :
- `node-fetch` : Pour les requ√™tes HTTP
- `tsx` : Pour ex√©cuter les scripts TypeScript

### 2. Configuration environnement

Copiez le fichier d'exemple :

\`\`\`bash
cp .env.scraper.example .env.local
\`\`\`

Modifiez `.env.local` et d√©finissez une cl√© secr√®te unique :

\`\`\`env
SCRAPER_SECRET=votre-cle-secrete-unique-ici
NEXT_PUBLIC_API_URL=http://localhost:4200
\`\`\`

---

## ‚öôÔ∏è Configuration

### Marques √† scraper

√âditez `scripts/cron-scraper.ts` pour activer/d√©sactiver les marques :

\`\`\`typescript
const SCRAPER_CONFIGS: ScraperConfig[] = [
  { brand: 'mini', maxPages: 3, enabled: true },      // ‚úÖ Activ√©
  { brand: 'bmw', maxPages: 5, enabled: true },       // ‚úÖ Activ√©
  { brand: 'mercedes', maxPages: 5, enabled: false }, // ‚ùå D√©sactiv√©
  // ...
];
\`\`\`

### Param√®tres par marque

- **brand** : Nom de la marque (mini, bmw, mercedes, audi, porsche, volkswagen)
- **maxPages** : Nombre maximum de pages √† scraper (~35 v√©hicules/page)
- **enabled** : Activer/d√©sactiver le scraping pour cette marque

---

## üìñ Utilisation

### Scraping manuel (test)

#### Scraper uniquement (sans import)

\`\`\`bash
# Scraper 2 pages de MINI
npm run scrape:mini

# Scraper 3 pages de BMW
npm run scrape:bmw

# Scraper 3 pages de Mercedes
npm run scrape:mercedes

# Scraper 3 pages d'Audi
npm run scrape:audi

# Scraper 2 pages de Porsche
npm run scrape:porsche

# Scraper 3 pages de Volkswagen
npm run scrape:volkswagen

# Scraper N pages d'une marque sp√©cifique
npx tsx scripts/scrape-importemoi.ts <brand> <pages>
# Exemple: npx tsx scripts/scrape-importemoi.ts porsche 5
\`\`\`

#### Scraper + Import dans Payload CMS

\`\`\`bash
# Via l'API (recommand√©)
curl -X POST http://localhost:3001/api/scrape-and-import \\
  -H "Content-Type: application/json" \\
  -H "Authorization: Bearer votre-cle-secrete" \\
  -d '{"brand": "mini", "maxPages": 2, "downloadImages": false}'
\`\`\`

### Import quotidien automatique

\`\`\`bash
# Ex√©cuter le cron job manuellement
npm run scrape:daily
\`\`\`

---

## ‚è∞ Automatisation

### M√©thode 1 : Crontab Linux/Mac

Ouvrez crontab :
\`\`\`bash
crontab -e
\`\`\`

Ajoutez cette ligne (2h du matin tous les jours) :
\`\`\`cron
0 2 * * * cd /chemin/vers/vanalexcars/frontend && npm run scrape:daily >> /var/log/scraper.log 2>&1
\`\`\`

### M√©thode 2 : PM2 (recommand√© pour production)

Installez PM2 :
\`\`\`bash
npm install -g pm2
\`\`\`

Cr√©ez un fichier `ecosystem.config.js` :
\`\`\`javascript
module.exports = {
  apps: [{
    name: 'vanalexcars-scraper',
    script: 'npm',
    args: 'run scrape:daily',
    cron_restart: '0 2 * * *', // 2h du matin
    autorestart: false,
    watch: false,
  }]
};
\`\`\`

D√©marrez :
\`\`\`bash
pm2 start ecosystem.config.js
pm2 save
pm2 startup
\`\`\`

### M√©thode 3 : Vercel Cron (si h√©berg√© sur Vercel)

Ajoutez dans `vercel.json` :
\`\`\`json
{
  "crons": [{
    "path": "/api/scrape-and-import",
    "schedule": "0 2 * * *"
  }]
}
\`\`\`

---

## üèóÔ∏è Architecture

### Flux de donn√©es

\`\`\`
ImporteMoi.fr
    ‚Üì (1) Fetch HTML
scripts/scrape-importemoi.ts
    ‚Üì (2) Extract JSON
    ‚Üì (3) Transform data
pages/api/scrape-and-import.ts
    ‚Üì (4) Check duplicates
    ‚Üì (5) Create/Update
Payload CMS (MongoDB)
    ‚Üì (6) Display
Frontend VanalexCars
\`\`\`

### Fichiers principaux

| Fichier | Description |
|---------|-------------|
| \`scripts/scrape-importemoi.ts\` | Script de scraping (extrait le JSON) |
| \`pages/api/scrape-and-import.ts\` | API d'import dans Payload CMS |
| \`scripts/cron-scraper.ts\` | Cron job automatique quotidien |

### Brand IDs ImporteMoi

Mapping des IDs de marques utilis√©s par ImporteMoi (v√©rifi√©s) :

| Marque | ID ImporteMoi | Slug VanalexCars |
|--------|---------------|------------------|
| MINI | 16338 | mini |
| BMW | 13 | bmw |
| Mercedes-Benz | 47 | mercedes |
| Audi | 9 | audi |
| Porsche | 57 | porsche |
| Volkswagen | 74 | volkswagen |

### Donn√©es scrap√©es

Pour chaque v√©hicule :
- ‚úÖ Informations de base (titre, marque, mod√®le, prix, ann√©e)
- ‚úÖ Caract√©ristiques (kilom√©trage, carburant, transmission)
- ‚úÖ Sp√©cifications (moteur, puissance, consommation, couleur)
- ‚úÖ √âquipements (liste des features)
- ‚úÖ M√©tadonn√©es (ID externe, r√©f√©rence, source, date de publication)
- ‚è≥ Images (t√©l√©chargement d√©sactiv√© par d√©faut)

---

## üîß Troubleshooting

### Probl√®me : "Non autoris√©" (401)

**Solution** : V√©rifiez que la cl√© \`SCRAPER_SECRET\` est correctement d√©finie dans \`.env.local\` et que vous l'utilisez dans le header \`Authorization\`.

### Probl√®me : "Aucun v√©hicule trouv√©"

**Causes possibles** :
- ImporteMoi a chang√© la structure HTML
- La marque n'a aucun v√©hicule disponible
- Probl√®me de connexion r√©seau

**Solution** : Testez manuellement :
\`\`\`bash
npm run scrape:mini
\`\`\`

### Probl√®me : V√©hicules en double

**Solution** : Le syst√®me utilise \`externalReference\` pour d√©tecter les doublons. V√©rifiez que ce champ est bien unique dans Payload CMS.

### Probl√®me : Import lent

**Solution** : Ajustez le nombre de pages (\`maxPages\`) et le d√©lai entre les requ√™tes dans le code.

---

## üìä Monitoring

### Logs

Les logs sont affich√©s dans la console lors de l'ex√©cution :

\`\`\`
üîç Scraping: https://importemoi.fr/mini-occasion-allemagne
‚úÖ 35 v√©hicules extraits du JSON
‚úÖ Page 1/2: 35 v√©hicules r√©cup√©r√©s
‚úÖ Cr√©√©: MINI Cooper S Cabrio
üìä R√©sum√© de l'import:
   Total: 70
   Cr√©√©s: 65
   Mis √† jour: 5
   Erreurs: 0
\`\`\`

### Statistiques

Apr√®s chaque import, vous recevez :
- Nombre total de v√©hicules trait√©s
- Nombre de cr√©ations
- Nombre de mises √† jour
- Nombre d'erreurs et d√©tails

---

## ‚ö†Ô∏è Consid√©rations l√©gales

**Important** : Le scraping de sites web peut violer les conditions d'utilisation (ToS) du site cible.

**Recommandations** :
1. ‚úÖ Utilisez avec mod√©ration (1 fois/jour maximum)
2. ‚úÖ Respectez les d√©lais entre les requ√™tes (rate limiting)
3. ‚úÖ Ne partagez pas les donn√©es scrap√©es publiquement
4. ‚ö†Ô∏è Contactez ImporteMoi pour une API officielle si possible

**Ce scraper est fourni √† titre √©ducatif et pour usage personnel uniquement.**

---

## üÜò Support

En cas de probl√®me :
1. V√©rifiez les logs
2. Testez manuellement avec \`npm run scrape:mini\`
3. V√©rifiez que Payload CMS est accessible
4. Consultez la documentation Payload CMS

---

## üìù TODO

- [ ] Impl√©menter le t√©l√©chargement d'images
- [ ] Ajouter un syst√®me de notification (email/Slack)
- [ ] Cr√©er un dashboard admin pour g√©rer le scraping
- [ ] Ajouter des tests unitaires
- [ ] Am√©liorer la gestion des erreurs r√©seau
